{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "576930ca",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeae4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import warnings\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, os\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import ticker\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe960d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set()\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e57a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "from file_handler import FileHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca66a99",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ba88015",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handler = FileHandler()\n",
    "train_sales = file_handler.read_csv(\"../data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02665369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01</th>\n",
       "      <td>87.284560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>6233.030493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>5693.112108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>5954.218834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>5337.751570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-27</th>\n",
       "      <td>9602.952466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-28</th>\n",
       "      <td>8174.953363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-29</th>\n",
       "      <td>7623.284305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-30</th>\n",
       "      <td>7891.348879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-31</th>\n",
       "      <td>9067.033184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Sales\n",
       "Date                   \n",
       "2013-01-01    87.284560\n",
       "2013-01-02  6233.030493\n",
       "2013-01-03  5693.112108\n",
       "2013-01-04  5954.218834\n",
       "2013-01-05  5337.751570\n",
       "...                 ...\n",
       "2015-07-27  9602.952466\n",
       "2015-07-28  8174.953363\n",
       "2015-07-29  7623.284305\n",
       "2015-07-30  7891.348879\n",
       "2015-07-31  9067.033184\n",
       "\n",
       "[942 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train_sales.groupby(\"Date\").agg({\"Sales\": \"mean\"})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42ab13f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_array = scaler.fit_transform(data)\n",
    "data['DataScaled'] = scaled_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f7876d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SIZE = len(data.DataScaled)\n",
    "WINDOW_SIZE = 48\n",
    "BATCH_SIZE = SIZE - WINDOW_SIZE * 2\n",
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16f9d444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the training set date series:  (846, 1)\n",
      "Shape of the validation set date series:  (96, 1)\n",
      "\n",
      "Shape of the training set logarithm of sales series:  (846,)\n",
      "Shape of the validation set logarithm of sales series in a stateless LSTM:  (96,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "DateTrain = data.index.values[0:BATCH_SIZE]\n",
    "DateValid = data.index.values[BATCH_SIZE:]\n",
    "XTrain = data.DataScaled.values[0:BATCH_SIZE].astype('float32')\n",
    "XValid = data.DataScaled.values[BATCH_SIZE:].astype('float32')\n",
    "\n",
    "# Obtain shapes for vectors of size (,1) for dates series\n",
    "\n",
    "DateTrain = np.reshape(DateTrain, (-1, 1))\n",
    "DateValid = np.reshape(DateValid, (-1, 1))\n",
    "\n",
    "print(\"Shape of the training set date series: \", DateTrain.shape)\n",
    "print(\"Shape of the validation set date series: \", DateValid.shape)\n",
    "print()\n",
    "print(\"Shape of the training set logarithm of sales series: \", XTrain.shape)\n",
    "print(\"Shape of the validation set logarithm of sales series in a stateless LSTM: \", XValid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8996dfcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([846, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(1234)\n",
    "# add extra dimension\n",
    "series = tf.expand_dims(XTrain, axis=-1)\n",
    "series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8daf8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(1,), dtype=tf.float32, name=None)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensor from each individual element\n",
    "dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39d1b600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# takes a window_size + 1 chunk from the slices\n",
    "dataset = dataset.window(WINDOW_SIZE + 1, shift=1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "15195481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[1, 2, 3, 4, 5]\n",
      "[2, 3, 4, 5, 6]\n",
      "[3, 4, 5, 6, 7]\n",
      "[4, 5, 6, 7, 8]\n",
      "[5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example of Window\n",
    "datasetEx = tf.data.Dataset.from_tensor_slices(tf.range(10))\n",
    "datasetEx = datasetEx.window(5, shift=1, drop_remainder=True)\n",
    "for window in datasetEx:\n",
    "    print([elem.numpy() for elem in window])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b348983",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = dataset.flat_map(lambda window: window.batch(WINDOW_SIZE + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce09a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(lambda window: (window[:-1], window[-1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d4bf28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.batch(BATCH_SIZE).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4097d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def windowed_dataset(series, window_size=WINDOW_SIZE, batch_size=BATCH_SIZE):\n",
    "  series = tf.expand_dims(series, axis=-1)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices(series)\n",
    "  dataset = dataset.window(window_size + 1, shift=1, drop_remainder=True)\n",
    "  dataset = dataset.flat_map(lambda window: window.batch(window_size + 1))\n",
    "  dataset = dataset.map(lambda window: (window[:-1], window[-1:]))\n",
    "  dataset = dataset.batch(batch_size).prefetch(1)\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "978bb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DatasetTrain = windowed_dataset(XTrain)\n",
    "DatasetVal = windowed_dataset(XValid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867511ed",
   "metadata": {},
   "source": [
    "Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad0cf1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(8, input_shape=[None, 1], return_sequences=True))\n",
    "model.add(LSTM(4, input_shape=[None, 1]))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"huber_loss\", optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "139181f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)        │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">533</span> (2.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m533\u001b[0m (2.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">533</span> (2.08 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m533\u001b[0m (2.08 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "970e08e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/06 01:02:15 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '09b5efa3f6db4c4ea88bba6ff3dc6563', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n",
      "2024/06/06 01:02:16 INFO mlflow.types.utils: MLflow 2.9.0 introduces model signature with new data types for lists and dictionaries. For input such as Dict[str, Union[scalars, List, Dict]], we infer dictionary values types as `List -> Array` and `Dict -> Object`. \n",
      "2024/06/06 01:02:16 INFO mlflow.types.utils: MLflow 2.9.0 introduces model signature with new data types for lists and dictionaries. For input such as Dict[str, Union[scalars, List, Dict]], we infer dictionary values types as `List -> Array` and `Dict -> Object`. \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret loss identifier: huber_loss",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mset_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLSTM\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mtensorflow\u001b[38;5;241m.\u001b[39mautolog()\n\u001b[1;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(DatasetTrain, epochs\u001b[38;5;241m=\u001b[39mEPOCHS, validation_data\u001b[38;5;241m=\u001b[39mDatasetVal, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:574\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m try_log_autologging_event(\n\u001b[0;32m    565\u001b[0m     AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_patch_function_start,\n\u001b[0;32m    566\u001b[0m     session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    570\u001b[0m     kwargs,\n\u001b[0;32m    571\u001b[0m )\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m patch_is_class:\n\u001b[1;32m--> 574\u001b[0m     patch_function\u001b[38;5;241m.\u001b[39mcall(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    576\u001b[0m     patch_function(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:165\u001b[0m, in \u001b[0;36mPatchFunction.call\u001b[1;34m(cls, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mcls\u001b[39m, original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 165\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:176\u001b[0m, in \u001b[0;36mPatchFunction.__call__\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_exception(e)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# Regardless of what happens during the `_on_exception` callback, reraise\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# the original implementation exception once the callback completes\u001b[39;00m\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:169\u001b[0m, in \u001b[0;36mPatchFunction.__call__\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_patch_implementation(original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:227\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.PatchWithManagedRun._patch_implementation\u001b[1;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mlflow\u001b[38;5;241m.\u001b[39mactive_run():\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanaged_run \u001b[38;5;241m=\u001b[39m create_managed_run()\n\u001b[1;32m--> 227\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_patch_implementation(original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanaged_run:\n\u001b[0;32m    230\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mend_run(RunStatus\u001b[38;5;241m.\u001b[39mto_string(RunStatus\u001b[38;5;241m.\u001b[39mFINISHED))\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\mlflow\\tensorflow\\__init__.py:1333\u001b[0m, in \u001b[0;36mautolog.<locals>.FitPatch._patch_implementation\u001b[1;34m(self, original, inst, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1327\u001b[0m         _logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   1328\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to log training dataset information to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1329\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMLflow Tracking. Reason: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1330\u001b[0m             e,\n\u001b[0;32m   1331\u001b[0m         )\n\u001b[1;32m-> 1333\u001b[0m history \u001b[38;5;241m=\u001b[39m original(inst, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m log_models:\n\u001b[0;32m   1336\u001b[0m     _log_keras_model(history, args)\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:557\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[1;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[0;32m    554\u001b[0m         original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[0;32m    555\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[1;32m--> 557\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:492\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[1;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    484\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    485\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_start,\n\u001b[0;32m    486\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         og_kwargs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m     original_fn_result \u001b[38;5;241m=\u001b[39m original_fn(\u001b[38;5;241m*\u001b[39mog_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mog_kwargs)\n\u001b[0;32m    494\u001b[0m     try_log_autologging_event(\n\u001b[0;32m    495\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_success,\n\u001b[0;32m    496\u001b[0m         session,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    500\u001b[0m         og_kwargs,\n\u001b[0;32m    501\u001b[0m     )\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\mlflow\\utils\\autologging_utils\\safety.py:554\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[1;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[0;32m    549\u001b[0m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[0;32m    551\u001b[0m     disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    552\u001b[0m     reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    553\u001b[0m ):\n\u001b[1;32m--> 554\u001b[0m     original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[0;32m    555\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\hp\\anaconda3\\Lib\\site-packages\\keras\\src\\losses\\__init__.py:196\u001b[0m, in \u001b[0;36mget\u001b[1;34m(identifier)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret loss identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret loss identifier: huber_loss"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"LSTM\")\n",
    "mlflow.tensorflow.autolog()\n",
    "history = model.fit(DatasetTrain, epochs=EPOCHS, validation_data=DatasetVal, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
